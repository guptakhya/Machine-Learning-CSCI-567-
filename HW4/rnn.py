# -*- coding: utf-8 -*-
"""Khyati_Gupta_8031075887.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-EVabwFeq2m1vvkBbYJt1q_0cqgUjQXA

Khyati Gupta - 8031075887
PA4

Read me:
Please run on Google Colab and use GPU T4.
The following code takes in the input date, extract some information from it in pre processing and computes stock price of that day based on the last 30 days dates. This is then used to predict for the dates given in test.csv and generates the predictions.csv output file
"""

import time
start_time = time.time()
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from datetime import datetime as dt, timedelta

def date_parser(date_col):
  for fmt in ('%m-%d-%Y', '%m/%d/%Y', '%m.%d.%Y'):
    try:
      return pd.to_datetime(date_col, format = fmt)
    except ValueError:
      pass

def process_dataset(dataset):
  dataset['day'] = dataset['date'].apply(lambda x: x.day)
  dataset['month'] = dataset['date'].apply(lambda x: x.month)
  dataset['year'] = dataset['date'].apply(lambda x: x.year)
  dataset['day_of_year'] = dataset['date'].apply(lambda x: x.dayofyear)
  dataset['weekday'] = dataset['date'].apply(lambda x: x.weekday())
  dataset['days_30'] = dataset['date'] - timedelta(days=30)
  dataset['week'] = dataset['date'].dt.isocalendar().week
  dataset['weekend'] = dataset['date'].dt.dayofweek.isin([5, 6]).astype(int)
  dataset['is_month_start'] = dataset['date'].dt.is_month_start.astype(int)
  dataset['is_month_end'] = dataset['date'].dt.is_month_end.astype(int)
  dataset['quarter_start'] = dataset['date'].apply(lambda x: int(x.is_quarter_start))
  dataset['is_year_start'] = dataset['date'].dt.is_year_start.astype(int)
  dataset['is_year_end'] = dataset['date'].dt.is_year_end.astype(int)
  dataset['days_from_today'] = (dt.now() - dataset['date']).dt.days
  dataset['quarter'] = dataset['date'].dt.quarter
  dataset['is_quarter_start'] = dataset['date'].dt.is_quarter_start
  dataset['is_quarter_start'] = dataset['is_quarter_start'].map({True: 1, False:0})
  dataset['is_quarter_end'] = dataset['date'].dt.is_quarter_end
  dataset['is_quarter_end'] = dataset['is_quarter_end'].map({True: 1, False:0})
  dataset['date'] = dataset['date'].astype(int)
  dataset['days_30'] = dataset['days_30'].astype(int)

  return dataset

"""Importing dataset"""

train_data, test_data = None, None
train_data = pd.read_csv("train.csv")
train_data['date'] = date_parser(train_data['date'])
#print(train_data.shape)

train_data_updated = None
train_data_updated = train_data.drop(['price'], axis=1)
train_data_updated = process_dataset(train_data_updated)

from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split

date_scaler = MinMaxScaler()
train_data_updated = date_scaler.fit_transform(train_data_updated)
output_scaler = MinMaxScaler()
scaled_labels = output_scaler.fit_transform(train_data['price'].array.reshape(-1,1))

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import LSTM
from tensorflow.keras.layers import Dropout
from tensorflow.keras.layers import GRU
import tensorflow.keras.optimizers as opt

timestep = 30
X_train = []
y_train =[]
for i in range(timestep, len(train_data_updated)):
  X_train.append(train_data_updated[i-timestep:i])
  y_train.append(scaled_labels[i])
#converting to numpy arrays:
X_train = np.array(X_train)
y_train = np.array(y_train)

#print(X_train.shape)
#print(y_train.shape)

rnn = None
rnn = Sequential()

rnn.add(LSTM(units = 256, return_sequences = True, input_shape = (X_train.shape[1], X_train.shape[2])))
rnn.add(Dropout(0.2))
rnn.add(LSTM(units = 128, return_sequences = True))
rnn.add(Dropout(0.2))
rnn.add(LSTM(units = 64, return_sequences = True))
rnn.add(Dropout(0.1))
rnn.add(GRU(64, return_sequences = True))
rnn.add(Dropout(0.1))
rnn.add(GRU(32))
rnn.add(Dense(units = 16, activation='relu'))
rnn.add(Dense(units = 1, activation='relu'))

rnn.compile(optimizer = opt.Adam(learning_rate=1e-3), loss = 'mse')

rnn.fit(X_train, y_train, epochs = 720, batch_size = 32)

testing_data, total_data = None, None
testing_data = pd.read_csv('test.csv')
testing_data['date'] = date_parser(testing_data['date'])
total_data = pd.concat([train_data[len(train_data)-timestep:],testing_data])
#print(total_data.shape)

test_data_updated = None
test_data_updated = total_data.drop(['price'], axis=1)
test_data_updated = process_dataset(test_data_updated)
#print(test_data_updated.shape)

test_data_updated = date_scaler.transform(test_data_updated)
X_test = []

for i in range(timestep, len(test_data_updated)):
    X_test.append(test_data_updated[i-timestep:i])

X_test = np.array(X_test)
#print(X_test.shape)

predictions = rnn.predict(X_test)

unscaled_predictions = output_scaler.inverse_transform(predictions)
'''final_prices = pd.concat([train_data['price'], pd.DataFrame(unscaled_predictions)], ignore_index = True)
plt.clf() #This clears the first prediction plot from our canvas

plt.plot(final_prices)
plt.plot(train_data['price'], label='train')
plt.legend()
'''

'''plt.clf() #This clears the first prediction plot from our canvas

plt.plot(unscaled_predictions, label = 'predict')
plt.plot(testing_data['price'], label='train')
plt.legend()
'''

'''from sklearn.metrics import mean_squared_error

rmse = 0

##### INPUT CODE HERE (~2 line of code) ######
rmse = mean_squared_error(testing_data['price'], unscaled_predictions, squared=False)
##############################################
print("The model performance for training set")
print("--------------------------------------")
print('RMSE is {}'.format(rmse))
print("\n")
'''

output_frame = pd.DataFrame({"date" : testing_data['date'], "price" : unscaled_predictions[:,0]})
output_frame.to_csv("predictions.csv", index=False)

print(time.time() - start_time)
